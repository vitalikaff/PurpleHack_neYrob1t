# PurpleHack_neYrob1t

# Файлы
1. preprocessing.ipynb - Предобработка данных
2. train_catboost.ipynb - Обучение модели
3. graphic - папка с графиками target_feature
4. dump_corr.csv - csv с корреляцией фич
5. cat_features - numpy array со списком категориальных данных

# Главный замысел
Всегда можно построить огромный ансамбль моделей и затюнить его, однако мы решили зайти с "умной" стороны, то есть со стороны анализа данных, чтобы получить наилучший результат. Проанализировав данные и затюнив правильно подобранную модель, мы бы получили выше результат, но не хватило времени и производительности пк.

# Анализ данных
Мы увидели дисбаланс классов 1 к 27.

Решили попробовать синтетическую генерацию экземпляров (SMOTE, ADASYN), p.s. В будущем решили отказаться, т.к. прирост был незначительный, но время на генерацию уходило много.
Дальше испытали метод главных компонентов (PCA). Который дал незначительное ухудшение. 

Очень сложно сделать с помощью этих мощных инструментов какой-то хороший результат без знания содержательного смысла фич.

Проверили фичи на уникальные значение и коллинеарность для упрощения данных и ускорения их обработки, обучения модели.

В результате: Удалили 88 фич с 1 уникальным значением, т.к. они не давали веса. Удалили 384 фич с очень высокой коллинеарности, т.к. датасет огромный, то потеря будет незначительной в обучении, но производительность увеличится (Иначе наши ноутбуки не могли обработать :) )

# Категориальные данные
Мы решили что если у фичи 2-5 уникальных значений, то с большей долей вероятности это категориальный признак
Если у фичи значения идут в возрастающем порядке, без пропусков, с единичным шагом, то вероятно это тоже категориальный признак
В результате: Мы отобрали 192 категориальных признаков

# Веса для фич
Мы решили более глубоко проанализировать влияние признаков на target (ознакомиться с графиками можно в папке graphics)
И увидели, как некоторые признаки сильно отличаются для клиентов, которые уйдут в отток, от тех, которые не уйдут.
Поэтому фичам, которые явно показывали отток клиента, давали большие веса (в файле train_catboost.ipynb)

# Обучение модели
По началу испытали 3 модели: случайные леса (RandomForestClassifier), логистическую регрессию (LogisticRegression), градиентный бустинг (CatBoostClassifier)
RandomForestClassifier - AUC 0.726
LogisticRegression - AUC 0.705
CatBoostClassifier - AUC 0.768
И мы так выбрали catboost.
Пробовали затюнить через gridsearch и optuna. И сделали выбор в пользу optuna, т.к. с gridsearch было очень долго.

# Результаты
Если бы было известно сколько приносит прибыли зарплатный клиент и сколько компания тратит на удержание клиента, то можно было бы рассчитать пропорцию чтобы recall и precision имели наибольший смысл.
Precision   Recall     F1         AUC
0.01620	    0.99857	   0.03188	  0.76784
